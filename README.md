# ctrLLM

**Controversial Topic Representation in LLM**

A comprehensive Python package for analyzing text diversity, bias, and controversial topic representation in language models.

---

# ctrLLM

**Controversial Topic Representation in LLM**

A comprehensive Python package for analyzing text diversity, bias, and controversial topic representation in language models.

---

## ğŸ¯ Purpose

This toolkit helps researchers and developers analyze how different sources (Wikipedia, Britannica, LLMs) represent controversial topics by measuring:

- **Text diversity** (vocabulary, semantic, lexical)
- **Perspective multiplexity** (multiple viewpoints)
- **Bias detection** (single vs. multi-perspective)
- **Content quality** (complexity, richness)
- **Rule-based discourse framing** (balance, narrative roles, harm)

---

## ğŸš€ Quick Start

### Installation

```bash
# Install package
pip install -e .

# Install dependencies (including OpenAI)
pip install -r requirements.txt

# Download Stanza models
python -c "import stanza; stanza.download('en')"

# Set OpenAI API key for LLM-based analysis
export OPENAI_API_KEY='your-openai-api-key'

```

### Basic Usage

```python
from ctrllm import TextMetrics, print_summary

# Initialize
metrics = TextMetrics(lang='en')

# Analyze text
text = "Your controversial topic text here..."
results = metrics.compute_all(text)

# Print results
print_summary(results)
```

---

## ğŸ“¦ Package Structure

```
ctrllm_package/
â”œâ”€â”€ ctrllm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ syntactic.py
â”‚   â”œâ”€â”€ semantic.py
â”‚   â”œâ”€â”€ entity.py
â”‚   â”œâ”€â”€ sentiment.py
â”‚   â”œâ”€â”€ argument.py
â”‚   â”œâ”€â”€ rule_based.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ demo.py
â”œâ”€â”€ test.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md

```

---

## ğŸ“Š Features

### Syntactic Analysis (`syntactic.py`)
- **Shannon Entropy** - Vocabulary distribution
- **POS Features** - Grammatical analysis
- **Vocabulary Complexity** - Word flexibility
- **Lexical Richness** - TTR, RTTR, CTTR

### Semantic Analysis (`semantic.py`)
- **Embedding Variance** - Semantic diversity
- **Pairwise Similarity** - Sentence similarity

### Entity Analysis (`entity.py`)
- **Entity Specificity** - Named entity density
- **Entity Distribution** - Person/Org/Location counts

### Sentiment Analysis (`sentiment.py`)
- **Sentiment Variance** - Emotional variability
- **Sentiment Distribution** - Positive/negative/neutral ratios

### **Argument Analysis (`argument.py`)**
- **Main vs. Fringe Perspective** - Main/fringe viewpoint ratio
- **Argument Diversity** - Argument topic diversity  
- **Argument Distinctness** - Cluster separation
- **Argumentativeness** - Argument density
- 
### **Rule-Based Analysis (`rule_based.py`)** 

A rule-based + LLM-assisted module for detecting higher-level discourse patterns not captured by syntactic or semantic metrics.

#### **1. Balanced Pro/Con Detection**
Identifies sentences that present **both pro and con viewpoints**, using LLM-based reasoning with contrastive patterns such as:

- â€œSome argue X, while others believe Y.â€
- â€œOn one hand A, on the other hand B.â€
- â€œProponents support X, whereas opponents claim Y.â€

**Outputs:**
- `balanced_ratio` â€” proportion of two-sided sentences  
- `num_balanced_sentences` â€” count  
- `balanced_sentences` â€” extracted examples  

---

#### **2. Narrative Roles Extraction**
Classifies entities into narrative roles:

- **Hero** â€” protagonist / positive agent  
- **Villain** â€” antagonist / cause of harm  
- **Victim** â€” harmed or disadvantaged groups  

**Uses LLM-based detection** (requires OpenAI API)

### Utilities (`utils.py`)
- **API Management** - Environment variables + explicit keys
- **Save/Load** - Pickle serialization

---

## ğŸ’» Usage Examples

### Example 1: Full Analysis

```python
from ctrllm import TextMetrics

metrics = TextMetrics(lang='en')
results = metrics.compute_all(text)

# Access specific metrics
print(results['shannon_entropy']['entropy'])
print(results['embedding_variance'])
print(results['entity_specificity'])
```

### Example 2: Individual Analyzers

```python
from ctrllm import SyntacticAnalyzer, SemanticAnalyzer, ArgumentAnalyzer

# Use individual classes
syntactic = SyntacticAnalyzer(lang='en')
syntactic.process_text(text)
entropy = syntactic.shannon_entropy()

semantic = SemanticAnalyzer()
semantic.set_sentences(sentences)
variance = semantic.embedding_variance()

# Argument analysis (LLM-based, requires OPENAI_API_KEY)
argument = ArgumentAnalyzer(
    lang='en',
    llm_model='gpt-4o-mini'
)
argument.process_text(text)
arg_results = argument.get_all_metrics(batch_delay=0.05)

print(f"Main ratio: {arg_results['main_vs_fringe']['main_ratio']:.3f}")
print(f"Diversity: {arg_results['argument_diversity']['arg_diversity']:.3f}")
```

---

## ğŸ“ Running Demo

```bash
python demo.py
```

---

## ğŸ“ Use Cases

1. **Compare information sources** (Wikipedia vs. Britannica vs. LLM)
2. **Detect bias** in controversial topic coverage
3. **Measure perspective diversity** in content
4. **Assess text quality** and complexity
5. **Academic research** on LLM representations

---

## ğŸ“š Dependencies

```
stanza                  # NLP processing
sentence-transformers   # Sentence embeddings
transformers           # Sentiment analysis
torch                  # PyTorch backend
numpy                  # Numerical operations
scikit-learn          # ML utilities
```

---

## ğŸ”§ API Reference

### Main Class: `TextMetrics`

```python
TextMetrics(lang='en', embedding_model='...', sentiment_model='...')

# Methods
.compute_all(text, **options)      # All metrics
.compute_syntactic(text)            # Syntactic only
.compute_semantic(text)             # Semantic only
.compute_entity(text)               # Entity only
.compute_sentiment(text)            # Sentiment only
```

### Individual Analyzers

See source code docstrings for detailed API documentation.

---

## ğŸ“„ License

MIT License - Free for academic and commercial use

---


